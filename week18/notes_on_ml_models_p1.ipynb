{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Machine Learning Models - Part 1 - Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "အပိုင်း ၃ ပိုင်းရှိတဲ့ ဒီ notes တွေမှာ အဓိကအားဖြင့် Machine Learning Model တွေကို အသုံးပြုရာမှာ သတိပြုရမဲ့ အောက်ပါ အကြောင်းအရာများကို ပြောပြပေးသွားမှာ ဖြစ်ပါတယ်။ \n",
    "\n",
    "* Feature Engineering \n",
    "* Model Engineering and\n",
    "* Coding Best Practices\n",
    "\n",
    "ဒီအပိုင်းက ပထမဆုံးအပိုင်း Feature Engineering ဖြစ်ပါတယ်။ \n",
    "\n",
    "$X$ ရော $y$ ပါရှိတဲ့ **supervised** Machine Learning ပဲ ဖြစ်ဖြစ်၊ $X$ တမျိုးပဲ ရှိတဲ့ **unsupervised** Machine Learning ပဲ ဖြစ်ဖြစ် Feature တွေ ရွေးချယ်မှုနဲ့ Engineering လုပ်တာတွေဟာ အရေးပါပါတယ်။ \n",
    "\n",
    "ဒါကြောင့် ဒီအပိုင်း မှာ \n",
    "\n",
    "* Feature Preprocessing Techniques\n",
    "* Feature Selection Techniques တွေနဲ့ \n",
    "* Dimensionality Reduction/Increment Techniques တွေ အကြောင်း ပြောမယ်။\n",
    "\n",
    "> Feature Engineering နဲ့ ဆိုင်ပေမဲ့ Data Type specific ဖြစ်တဲ့ Text/Image/Audio/Timeseries Data Manipulation ကိုတော့ Model Engineering နဲ့ အတူပြောမယ်။"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as sk_pp\n",
    "from sklearn import datasets as sk_ds\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X, ds_y = sk_ds.fetch_openml(name=\"credit-g\", as_frame=True, return_X_y=True)\n",
    "df_X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ဒီ dataset မှာ null value `NaN` ပါ/မပါကို အရင် ကြည့်ရမယ်။ ကြည့်ပုံကြည့်နည်းကတော့ `pandas.DataFrame` ရဲ့ `isna` method နဲ့ပါပဲ။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_y.isna().any()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ဒီတော့ ဒီ data မှာ null value `NaN` မပါတာကို တွေ့ရမယ်။ ပါခဲ့ရင် `pandas.DataFrame.fillna` method နဲ့ ဖြည့်တာ (သို့မဟုတ်) `pandas.DataFrame.dropna` နဲ့ ဖြုတ်ချတာ တခုခု လုပ်ရမယ်။"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`sklearn` ပဲ ဖြစ်ဖြစ်၊ `XGBoost` ပဲ ဖြစ်ဖြစ်၊ `lightgbm` ပဲ ဖြစ်ဖြစ် ... အခု ခေတ်စားနေတဲ့ Deep Learning `pytorch`/`tensorflow` ပဲ ဖြစ်ဖြစ် numeric value မဟုတ်ရင် ဘာမှ လုပ်လို့ မရဘူး။ ဒါကြောင့် Numeric Value မဟုတ်တဲ့ Categorical Feature တွေကို Encode လုပ်ပေးရတယ်။\n",
    "\n",
    "ဒီလို encode လုပ်ရာမှာ \n",
    "\n",
    "* One-Hot Encoding နဲ့ \n",
    "* Ordinal Encoding (Label Encoding) ဆိုပြီး ၂ မျိုး ရှိတယ်။"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knowing `dtypes`\n",
    "ဘာပဲဖြစ်ဖြစ် encode မလုပ်ခင်မှာ ဘယ် column တွေက ဘာ data type လဲဆိုတာ သိဖို့လိုတယ်။ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data type ပေါ်မူတည်ပြီး column တွေကို ရွေးနိုင်ဖို့ `pandas.DataFrame.select_dtypes` method ကို သုံးနိုင်တယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_category = df_X.select_dtypes(include=[\"category\"])\n",
    "df_X_category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_number = df_X.select_dtypes(include=[\"number\"])\n",
    "df_X_number.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensuring data nature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data nature ဆိုတာ categorical လား၊ numeric လားကို ဆိုလိုတယ်။ \n",
    "\n",
    "လက်တွေ့ဘဝမှာ computer ထဲ သိမ်းထားတဲ့ `dtypes` နဲ့ data nature က အမြဲတူမနေနိုင်ဘူး။\n",
    "\n",
    "တချို့ dataset တွေမှာ numeric value ဖြစ်နေပေမဲ့ categorical data ဖြစ်နေတတ်တယ်။ \n",
    "\n",
    "> ဥပမာ McDonald's က အရောင်း transaction ဆိုရင် Combo 1, Combo 2, Combo 3 ကို 1, 2, 3 လို့ encode လုပ်ထားတဲ့ column ပါလာတာမျိုး။ ဒါကြောင့် some numbers may be categories လို့ အမြဲသတိထားရမယ်\n",
    "\n",
    "ပြီးတော့ ... \n",
    "\n",
    "* Categorical မှာမှ order ရှိတဲ့ ordinal (XS/S/M/L/XL/XXL) လား၊ order မရှိတဲ့ norminal (blue/green/red) လား ထပ်ခွဲနိုင်ပြီး\n",
    "\n",
    "* Numeric မှာမှ integer နဲ့ float ဆိုပြီး ထပ်ခွဲနိုင်တယ်။\n",
    "\n",
    "ဒါတွေကို သိနိုင်ဖို့ `pandas.Series.unique` method နဲ့ `pandas.Series.nunique` method တွေကို သုံးပြီး ကြည့်နိုင်တယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_unique_values = {c: [df_X[c].unique()] for c in df_X.columns}\n",
    "df_col_to_unique_values = pd.DataFrame(data=col_to_unique_values, index=[\"unique_values\"]).T\n",
    "df_col_to_unique_values.loc[:, \"unique_count\"] = df_col_to_unique_values.apply(lambda x : df_X[x.name].nunique(), axis=1)\n",
    "df_col_to_unique_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "အထူးသဖြင့် `unique_count` နည်းတဲ့ numeric column တွေကို အဓိကထားပြီး ကြည့်ရမယ်။ \n",
    "\n",
    "> ဒီ dataset မှာတော့ categorical nature နဲ့ numeric column မရှိဘူး။ ဥပမာ ... `residence_since` ဆိုရင် 4.0 က 2.0 ထက် ကြီးတယ်။ categorical မဟုတ်ဘူး။ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "တခါတလေမှာ `pandas.Series.unique` အစား `pandas.Series.value_counts` function ကို သုံးနိုင်တယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_y.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "အလွယ်အားဖြင့် ordinal data တွေကို ordinal encode လုပ်ပြီး norminal data တွေကို one-hot encode လုပ်ရမယ်။\n",
    "\n",
    "အခု ဒါတွေကို သိအောင် data ကို explore လုပ်ရမယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_X_category.columns:\n",
    "    print (\"Column : {}\".format(c))\n",
    "    print (df_X_category[c].dtype.categories)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ဒီနေရာမှာ မြင်သာတဲ့ ordinal data တွေက အောက်ပါတို့ ဖြစ်တယ်။ သူတို့နဲ့အတူ အစီအစဉ်ကိုပါ ပြထားတယ်။\n",
    "\n",
    "* `credit_history` : `['no credits/all paid', 'all paid', 'existing paid', 'delayed previously', 'critical/other existing credit']`\n",
    "* `savings_status` : `['no known savings', '<100', '100<=X<500', '500<=X<1000', '>=1000']` -- ဒီနေရာမှာ ပြန်စီလိုက်တာကို သတိပြုပါ\n",
    "\n",
    "တခြား ordinal data တွေ ရှိနေနိုင်သေးပေမဲ့ ကျန်တာကို ဒီနေ့အဖို့ one-hot encoding ပဲ လုပ်လိုက်မယ်။\n",
    "\n",
    "> `personal_status` ကနေပြီး `gender` ထုတ်လို့ ရတာကို သတိထားပါ။ အိမ်စာအနေနဲ့ ထုတ်ကြည့်ပါ။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(index=df_X.index, data=None)\n",
    "\n",
    "ordinal_columns = [\"credit_history\", \"savings_status\"]\n",
    "oe = sk_pp.OrdinalEncoder(\n",
    "    # အောက်က categories parameter မှာ array-like of array-like (list of list) ထည့်ပေးရတာ သတိပြုပါ။\n",
    "    categories=[\n",
    "        ['no credits/all paid', 'all paid', 'existing paid', 'delayed previously', 'critical/other existing credit'],\n",
    "        ['no known savings', '<100', '100<=X<500', '500<=X<1000', '>=1000']\n",
    "    ], \n",
    "    # handle_unknown က သိပ်အရေးကြီးတယ်။ ဒါမပါသွားရင် production ကျမှ ပြဿနာ တက်တတ်တယ်။ default is \"error\"\n",
    "    handle_unknown=\"use_encoded_value\", \n",
    "    unknown_value=np.nan\n",
    ")\n",
    "\n",
    "df_features.loc[:, [\"oe_{}\".format(c) for c in ordinal_columns]] = oe.fit_transform(df_X[ordinal_columns])\n",
    "df_features.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Err** အပေါ်က cell က code မှာ သီအိုရီ/သဘောတရား အမှားတခု ပါနေတယ်။ \n",
    "\n",
    "> စာသင်ချိန်အတွင်းမှာပဲ ရအောင် ရှာပါ။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection as sk_ms\n",
    "\n",
    "df_X_tr, df_X_ts, ds_y_tr, ds_y_ts = sk_ms.train_test_split(df_X, ds_y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "df_feat_tr = pd.DataFrame(data=None, index=df_X_tr.index)\n",
    "df_feat_ts = pd.DataFrame(data=None, index=df_X_ts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_columns = [\"credit_history\", \"savings_status\"]\n",
    "oe = sk_pp.OrdinalEncoder(\n",
    "    # အောက်က categories parameter မှာ array-like of array-like (list of list) ထည့်ပေးရတာ သတိပြုပါ။\n",
    "    categories=[\n",
    "        ['no credits/all paid', 'all paid', 'existing paid', 'delayed previously', 'critical/other existing credit'],\n",
    "        ['no known savings', '<100', '100<=X<500', '500<=X<1000', '>=1000']\n",
    "    ], \n",
    "    # handle_unknown က သိပ်အရေးကြီးတယ်။ ဒါမပါသွားရင် production ကျမှ ပြဿနာ တက်တတ်တယ်။ default is \"error\"\n",
    "    handle_unknown=\"use_encoded_value\", \n",
    "    unknown_value=np.nan\n",
    ")\n",
    "oe.fit(df_X_tr[ordinal_columns])\n",
    "ordinal_features = [\"oe_{}\".format(c) for c in ordinal_columns]\n",
    "\n",
    "df_feat_tr.loc[:, ordinal_features] = oe.transform(df_X_tr[ordinal_columns])\n",
    "# see ? you can never ever fit with whole dataset; \n",
    "df_feat_ts.loc[:, ordinal_features] = oe.transform(df_X_ts[ordinal_columns])\n",
    "\n",
    "df_feat_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norminal_columns = [c for c in df_X_category.columns if c not in ordinal_columns]\n",
    "\n",
    "ohe = sk_pp.OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "ohe.fit(df_X_tr[norminal_columns])\n",
    "\n",
    "norminal_features = ohe.get_feature_names_out()\n",
    "df_feat_tr.loc[:, norminal_features] = ohe.transform(df_X_tr[norminal_columns])\n",
    "df_feat_ts.loc[:, norminal_features] = ohe.transform(df_X_ts[norminal_columns])\n",
    "df_feat_tr.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding ပြီးသွားတော့ Scaling ပေါ့။ \n",
    "\n",
    "Scaling မှာ `StandardScaler`, `MinMaxScaler` နဲ့ `MaxAbsScaler` ဆိုပြီး ရှိတယ်။ \n",
    "\n",
    "* `StandardScaler` က Standardization (or) Mean Removal လုပ်ဖို့ သုံးတယ်။ mean ကို နှုတ်ပြီး standard deviation နဲ့ စားတာပါပဲ။\n",
    "* `MinMaxScaler` ကျတော့ အငယ်ဆုံးကို 0 (သုည)၊ အကြီးဆုံးကို 1 (တစ်) အတွင်း ဝင်အောင် scale လုပ်တာ။ min ကို နှုတ်ပြီး (max - min) နဲ့ စားတာပါပဲ။\n",
    "* `MaxAbsScaler` ကျတော့ အကြီးဆုံးကို 1 (တစ်) ဖြစ်အောင် scaler လုပ်တာ။ တန်ဖိုးကို max နဲ့ စားတာပါပဲ။\n",
    "\n",
    "ဒီနေရာမှာ scale လုပ်တာ မဟုတ်ပဲ Data တွေကို နေရာရွှေ့ပေးတဲ့ နောက်ထပ် transformer တမျိုးကိုလဲ မှတ်ထားသင့်တယ်။ သူက `QuantileTransformer`။ သူ့မှာ variant ၂ မျိုးရှိတယ်။ `output_distribution=\"uniform\"` နဲ့ `output_distribution=\"normal\"` ဆိုပြီးတော့။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = sk_pp.StandardScaler()\n",
    "mms = sk_pp.MinMaxScaler()\n",
    "mas = sk_pp.MaxAbsScaler()\n",
    "\n",
    "numerical_columns = list(df_X_number.columns) + ordinal_features\n",
    "ss_features = [\"ss_{}\".format(c) for c in numerical_columns]\n",
    "mms_features = [\"mms_{}\".format(c) for c in numerical_columns]\n",
    "mas_features = [\"mas_{}\".format(c) for c in numerical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_tr.loc[:, ordinal_features] = df_feat_tr[ordinal_features]\n",
    "df_X_ts.loc[:, ordinal_features] = df_feat_ts[ordinal_features]\n",
    "\n",
    "df_feat_tr.drop(ordinal_features, axis=\"columns\", inplace=True)\n",
    "df_feat_ts.drop(ordinal_features, axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_tr.loc[:, ss_features] = ss.fit_transform(df_X_tr[numerical_columns])\n",
    "df_feat_tr.loc[:, mms_features] = mms.fit_transform(df_X_tr[numerical_columns])\n",
    "df_feat_tr.loc[:, mas_features] = mas.fit_transform(df_X_tr[numerical_columns])\n",
    "\n",
    "df_feat_ts.loc[:, ss_features] = ss.fit_transform(df_X_ts[numerical_columns])\n",
    "df_feat_ts.loc[:, mms_features] = mms.fit_transform(df_X_ts[numerical_columns])\n",
    "df_feat_ts.loc[:, mas_features] = mas.fit_transform(df_X_ts[numerical_columns])\n",
    "\n",
    "df_feat_tr.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "တချို့ model တွေက scaling လုပ်ထားတဲ့ feature နဲ့မှ အဆင်ပြေပြီး တချို့ model တွေက မလိုဘူး။\n",
    "\n",
    "> လိုတဲ့ model တွေက linear model တွေနဲ့ svm/svc model တွေဖြစ်တယ်။\n",
    ">\n",
    "> ဘယ် model တွေက scaling လုပ်ပေးစရာ မလိုဘူးလဲ ? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "နောက်ဆုံးအနေနဲ့ label ကို encode လုပ်ရမယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = sk_pp.LabelEncoder()\n",
    "y_tr = le.fit_transform(ds_y_tr)\n",
    "y_ts = le.transform(ds_y_ts)\n",
    "le.classes_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ကျနော်တို့တွေက `\"bad\"` ကို ရှာချင်တာ ဖြစ်တာမို့ label ကို 1 to 0 and 0 to 1 လှည့်ပါမယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = 1 - y_tr\n",
    "y_ts = 1 - y_ts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection လို့ ပြောသော်လည်းပဲ လိုအပ်ရင် preprocessing ကို ပြန်သွားရမှာ ဖြစ်တယ်။ \n",
    "\n",
    "ဒီ Section မှာလဲ ရှေ့ကို ကျော်ပြီး baseline သဘောနဲ့ modelling လုပ်တာ ရှိတယ်။\n",
    "\n",
    "> ဒါတွေကြောင့်မို့လို့ Data Science Process ဟာ iterative/recursive process ဖြစ်တယ်။ တခုပြီးမှ နောက်တခု သွားတာမျိုး မရှိဘူး။"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "အရိုးဆုံး feature selection technique က univariate feature selection ဖြစ်တယ်။ အဲဒီအတွက် `SelectKBest` သို့မဟုတ် `SelectPercentile` ကို သုံးတယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection as sk_fs\n",
    "\n",
    "skb = sk_fs.SelectKBest(score_func=sk_fs.f_classif, k=50)\n",
    "skb.fit(df_feat_tr, y_tr)\n",
    "skb.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-based Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ကိုယ်သုံးမဲ့ model ကို ကြိုသိရင် model နဲ့ Feature Selection လုပ်၊ ပြီးရင် Model မှာ ပြန်စမ်း ... ရလာတာနဲ့ Feature Selection ပြန်လုပ်လို့ရတယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as sk_lm \n",
    "sfm = sk_fs.SelectFromModel(estimator=sk_lm.SGDClassifier(penalty=\"elasticnet\", max_iter=10000, n_jobs=4), threshold=\"median\", prefit=False)\n",
    "sfm.fit(df_feat_tr, y_tr)\n",
    "df_feat_tr.columns[sfm.get_support()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "သတိထားရမှာက `SelectFromModel` က model တိုင်းနဲ့ အလုပ်မလုပ်ဘူး။ ဥပမာ SVM model တွေနဲ့ အလုပ်မလုပ်ဘူး။\n",
    "\n",
    "> ဘာဖြစ်လို့လဲဆိုတော့ `coef_` or `feature_importances_` attributes တွေ model မှာ ရှိမှ အလုပ်လုပ်တယ်။"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ဒီတခုကတော့ model တိုင်းနဲ့ အလုပ်လုပ်တယ်။\n",
    "\n",
    "> သို့သော် ... ပိုကြာတယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "nusvc = svm.NuSVC(class_weight={0: 1, 1: 5}, random_state=42)\n",
    "sfs = sk_fs.SequentialFeatureSelector(\n",
    "    estimator=nusvc, \n",
    "    n_features_to_select=50, \n",
    "    # backward means start with all and remove\n",
    "    # forward means start with 1 and add\n",
    "    direction=\"backward\", \n",
    "    cv=10, \n",
    "    n_jobs=4\n",
    ")\n",
    "sfs.fit(df_feat_tr, y_tr)\n",
    "df_feat_tr.columns[sfs.get_support()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction/Increment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ဒီနောက်ဆုံးပိုင်းကတော့ dimensionality (number of column) ကို လျှော့/တိုးတဲ့ အပိုင်းပါပဲ။ \n",
    "\n",
    "Dimensionality Reduction အတွက်\n",
    "\n",
    "* KMeans\n",
    "* SVD နဲ့\n",
    "* PCA တို့ကို သုံးလို့ရပြီး ... \n",
    "\n",
    "Dimensionality Increment အတွက်ကတော့ KMeans တမျိုးတည်းကို သုံးလို့ ရပါတယ်။\n",
    "\n",
    "> Time-series တွေကို dimensionality reduction လုပ်ဖို့ သုံးတာက ဘာပါလိမ့်နော် ... ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition as sk_decom\n",
    "\n",
    "svd = sk_decom.TruncatedSVD(n_components=20, n_iter=10, random_state=42)\n",
    "pca = sk_decom.PCA(n_components=20, random_state=42)\n",
    "\n",
    "svd.fit(df_feat_tr.values)\n",
    "pca.fit(df_feat_tr.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "အခုနောက်ပိုင်း အသစ်ပေါ်တာအနေနဲ့ t-SNE ဟာ SVD/PCA တို့လို linear method မဟုတ်ပဲ non-linear method ဖြစ်တယ်။ \n",
    "\n",
    "> သူအလုပ်လုပ်ပုံက SVM နဲ့ ပြောင်းပြန်လို့ အလွယ်မှတ်နိုင်တယ်။ \n",
    "\n",
    "> t-SNE ထက် မြန်တဲ့ UMAP ဆိုတာလဲ ရှိသေးတယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42, n_jobs=4)\n",
    "tsne = tsne.fit(df_feat_tr.values)\n",
    "tsne.kl_divergence_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kl_divergence_ (cross entropy ပဲ ဆိုကြပါစို့) က နည်းလေ information များလေ၊ similarity betweenလို့ ယူဆနိုင်တယ်။\n",
    "\n",
    "> သတိထားရမှာက t-SNE ဟာ visualization ကို support လုပ်ဖို့ ထုတ်ထားတဲ့ algorithm မို့လို့ n_component က 3 ထက် ကြီးလို့ မရဘူး။"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> လေ့ကျင့်ခန်းအနေနဲ့ အပေါ်က ရထားတဲ့ feature ၅၀ (ကြိုက်ရာ ၅၀) နဲ့ svd/pca တခုက feature 20 တို့ ပေါင်းပြီး model တခု ဆောက်ကြည့်ပါ။"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster as sk_clus\n",
    "\n",
    "kmeans = sk_clus.KMeans(n_clusters=20, max_iter=1000, random_state=42)\n",
    "\n",
    "kmeans.fit(df_feat_tr.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc. Proofs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Euclidean Distance of Normalized Vectors $\\propto$ Cosine Distance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with definitions.\n",
    "\n",
    "Cosine can be derived from definition of dot-product:\n",
    "\n",
    "$X \\cdot Y = cos(\\theta)\\|X\\|\\|Y\\|$\n",
    "\n",
    "$\\Rightarrow cos(\\theta) = \\frac{X \\cdot Y}{\\|X\\|\\|Y\\|}$ \n",
    "\n",
    "> Also take note that dot-product $X \\cdot Y$ is a scalar and is the same as $X^T Y$\n",
    "\n",
    "When normalized, both $\\|X\\|$ and $\\|Y\\|$ becomes 1 $\\because$ it is the definition of normalization.\n",
    "\n",
    "$\\therefore cos(\\theta) = X \\cdot Y$ when both $X$ and $Y$ are normalized unit vectors.\n",
    "\n",
    "> The above $cos(\\theta)$ is cosine similarity because $cos(0)=1$ and $cos(\\pi/2)=0$.\n",
    ">\n",
    "> Cosine distance is given by $1 - cos(\\theta)$.\n",
    "\n",
    "Euclidean distance is Norm-2 of $X-Y$. \n",
    "\n",
    "$dist(X, Y) = \\|X - Y\\|_2$\n",
    "\n",
    "Let's square it.\n",
    "\n",
    "$dist(X, Y)^2 = \\|X - Y\\|_2^2$\n",
    "\n",
    "$= (X-Y)^T(X-Y)$\n",
    "\n",
    "> $ \\because V^T V = \\sum{v_i^2}$ by definition.\n",
    "\n",
    "$= (X^T-Y^T)(X-Y)$\n",
    "\n",
    "$= (X^T X) - (X^T Y) - (Y^T X) + (Y^T Y)$ \n",
    "\n",
    "> note that the two terms in middle are scaler and the same, i.e. $(X^T Y) = (Y^T X)$.\n",
    "\n",
    "$= (1) - (X^T Y) - (X^T Y) + (1)$\n",
    "\n",
    "$= 2 - 2 (X^T Y)$\n",
    "\n",
    "$= 2 (1 - X^T Y)$\n",
    "\n",
    "$= 2 (1 - X \\cdot Y)$\n",
    "\n",
    "$= 2 (1 - cos(\\theta))$\n",
    "\n",
    "$= 2 \\times$ cosine distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-dsup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
