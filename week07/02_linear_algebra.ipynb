{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra\n",
    "\n",
    "ဒီနေ့ Linear Algebra ကို ဆွေးနွေးမှာ ဖြစ်တယ်။ \n",
    "\n",
    "1. ပထမဆုံး Linear Algebra ကို အသုံးချပြီး PCA နဲ့ SVD လုပ်တာကို လက်တွေ့လုပ်ကြည့်ကြမယ်။\n",
    "2. ပြီးရင် Optization နဲ့ Search ကြားက ဆက်သွယ်ချက်ကို ပြောမယ်။\n",
    "3. Matrix နဲ့ Vector တွေ အကြောင်းကို ဆက်မယ်။ \n",
    "4. နောက်မှာ Transformation တွေကို ဆက်ကြည့်ပြီး ... \n",
    "5. Eigen values/Eigen vectors တွေနဲ့ အဆုံးသတ်မယ်။ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import get_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = get_image()\n",
    "plt.imshow(img_1, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (img_1.ndim, img_1.shape, img_1.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "U, s, Vt = linalg.svd(img_1)\n",
    "print (U.ndim, U.shape, U.size)\n",
    "print (s.ndim, s.shape, s.size)\n",
    "print (Vt.ndim, Vt.shape, Vt.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will give a value error\n",
    "approx_1 = U @ s @ Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's just use the first 64 values of s and first 64 rows of Vt\n",
    "k = 32\n",
    "s_ = s[:k]\n",
    "Vt_ = Vt[:k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Sigma = np.zeros((U.shape[1], Vt_.shape[0]))\n",
    "np.fill_diagonal(Sigma, s_)\n",
    "\n",
    "approx_1 = np.matmul(U, np.matmul(Sigma, Vt_)) # U @ Sigma @ Vt_\n",
    "plt.imshow(approx_1, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"total size of U, s_ and Vt_ is : \")\n",
    "print (U.size + s_.size + Vt_.size)\n",
    "print (\"original image size is : \")\n",
    "print (img_1.size)\n",
    "print (\"compression ratio : {}/{} = {}\".format(U.size + s_.size + Vt_.size, img_1.size, (U.size + s_.size + Vt_.size)/img_1.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do for all colors\n",
    "img_1 = get_image(grayscale=False)\n",
    "img_1_transposed = np.transpose(img_1, (2, 0, 1))\n",
    "U, s, Vt = linalg.svd(img_1_transposed)\n",
    "s_ = s[:, :k]\n",
    "Vt_ = Vt[:, :k, :]\n",
    "Sigma = np.zeros((3, 768, 1024))\n",
    "for j in range(0, 3):\n",
    "    np.fill_diagonal(Sigma[j, :, :], s_[j, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_img = np.matmul(U, np.matmul(Sigma[..., :k], Vt_[..., :k, :])) # U @ Sigma[..., :k] @ Vt_[..., :k, :]\n",
    "print (approx_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(approx_img, (1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"total size of U, s_ and Vt_ is : \")\n",
    "print (U.size + s_.size + Vt_.size)\n",
    "print (\"original image size is : \")\n",
    "print (img_1.size)\n",
    "print (\"compression ratio : {}/{} = {}\".format(U.size + s_.size + Vt_.size, img_1.size, (U.size + s_.size + Vt_.size)/img_1.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait! What? Sorcery?\n",
    "\n",
    "တကယ့်လက်တွေ့မှာ jpeg/png, mpeg, mp3 compression တွေဟာ (ဒီထက် အဆင့်မြင့်ပေမဲ့) ဒီဟာနဲ့ သဘောတရားတူတဲ့ Linear Algebra အခြေခံ နည်းလမ်းတွေကို အသုံးပြုထားတာ ဖြစ်ပါတယ်။\n",
    "\n",
    "Data Science မှာကတော့ Data တွေဟာ Dimension တွေ သိပ်များနေရင် (column တွေ သိပ်များနေရင်) ချုံ့ပစ်ဖို့ Dimensionality Reduction Technique အနေနဲ့ အသုံးပြုကြပါတယ်။ PCA ရယ် SVD ရယ်ဆိုပြီး လူသိများပါတယ်။ တကယ်တမ်းကတော့ အဲဒီ ၂ ခုဟာ ခပ်ဆင်ဆင်ပါပဲ။ နောက်ပိုင်းမှာ model ဆောက်တဲ့နားရောက်ရင် အဲဒါတွေကို အကျယ်ပြောပါမယ်။ \n",
    "\n",
    "လောလောဆယ်ကတော့ Linear Algebra အကြောင်းကို အသေးစိတ် လေ့လာရအောင်ပါ။"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a9c1e998c7d6d5f29587b2c70e9bd488bb486b902354401efc27ca8457f04e9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py37-dsup')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
