{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 20 - Outro\n",
        "\n",
        "မင်္ဂလာပါ၊ ဒီနေ့ နောက်ဆုံးပိတ် အိတ်နဲ့လွယ် ... Neural Network တွေကို စမ်းရေး၊ စမ်းသုံးကြည့်ကြမယ်။ \n",
        "\n",
        "ပထမဆုံး ရင်းနှီးပြီးသားဖြစ်တဲ့ myanmar-digits နဲ့ စပါမယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggRYFMDmxl49",
        "outputId": "5b00842d-4099-4885-ac61-3701f72b75fa"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/neolaw84/myanmar-digits.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D1AsNbgxqfi",
        "outputId": "7ab69256-2ac3-41de-e8e3-c939829b3938"
      },
      "outputs": [],
      "source": [
        "%cd myanmar-digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA7H9pbmyfD6",
        "outputId": "216a15de-8cd7-4e26-d9dc-9681f8f67aa9"
      },
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DETx3lsDx4v_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datetime import datetime \n",
        "\n",
        "from sklearn import feature_selection as fs, model_selection as ms, metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from myanmar_digits import load_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparation\n",
        "\n",
        "### Import necessary modules\n",
        "\n",
        "Neural Network ကို **pytorch** library ကို အသုံးပြုပြီး ရေးသားပါမယ်။ \n",
        "\n",
        "ဒီအတွက် `torch`, `torch.nn` နဲ့ `torchvision` တို့ထဲက လိုအပ်တာတွေကို import လုပ်ပါတယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# check device to use CUDA (GPU programming) if available\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set parameters\n",
        "\n",
        "Neural Network တခုမှာ အရေးပါတဲ့ parameter တွေကတော့\n",
        "\n",
        "* learning_rate \n",
        "* batch_size နဲ့\n",
        "* number_of_epoch တို့ပဲ ဖြစ်တယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZSVTKGGyV6E"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "RANDOM_SEED = 42\n",
        "LEARNING_RATE = 0.002\n",
        "BATCH_SIZE = 4\n",
        "N_EPOCHS = 50\n",
        "\n",
        "IMG_SIZE = 48\n",
        "N_CLASSES = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data\n",
        "\n",
        "Data ကို load လုပ်ပါမယ်။ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX7Iv4BEaWVZ",
        "outputId": "4ddc7bbf-ff11-4271-e1cd-6451c97100a8"
      },
      "outputs": [],
      "source": [
        "X, y = load_data(as_frame=False, return_X_y=True, num_classes=N_CLASSES)\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`torch` က `sklearn` လို မဟုတ်ပဲ 2D data structure (2d tensor) တင်မက 3D data structure (3d tensor) နဲ့ အဆင့်မြင့် kD data structure တွေကိုပါ ကိုင်တွယ်နိုင်တာမို့ရယ်၊ convolution လုပ်ချင်တာမို့ရယ် `X` ကို တလက်စတည်း 48x48 image တွေပါတဲ့ array ကြီးအဖြစ် `reshape` လုပ်လိုက်ပါတယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2_ZsIrxawCT"
      },
      "outputs": [],
      "source": [
        "X = (255 - X)/255.0\n",
        "X = X.reshape( -1, 48, 48 )\n",
        "y = y.astype(np.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "_wVc0vowbhMX",
        "outputId": "fa33febf-ecda-43e0-cd75-eb3d31fa571a"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X[1000], cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = X[:, 8:-8, 8:-8]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train/Test splitting\n",
        "\n",
        "data ကို load လုပ်ပြီးရင် မမေ့မလျော့ train/test split လုပ်ပါ။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg_tWIbgeB54"
      },
      "outputs": [],
      "source": [
        "tr_X, ts_X, tr_y, ts_y = ms.train_test_split(X, y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create DataLoaders\n",
        "\n",
        "နောက်တဆင့်မှာ torch ကသုံးတဲ့ DataLoader တွေအဖြစ်ကို အသွင်ပြောင်းရပါမယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuClhAVfz6KF"
      },
      "outputs": [],
      "source": [
        "tr_tensor_x = torch.Tensor(tr_X) # transform to torch tensor\n",
        "tr_tensor_y = torch.Tensor(tr_y).long()\n",
        "\n",
        "ts_tensor_x = torch.Tensor(ts_X) # transform to torch tensor\n",
        "ts_tensor_y = torch.Tensor(ts_y).long()\n",
        "\n",
        "my_dataset = TensorDataset(tr_tensor_x, tr_tensor_y) # create your datset\n",
        "my_dataloader = DataLoader(my_dataset, batch_size=BATCH_SIZE) # create your dataloader\n",
        "\n",
        "ts_dataset = TensorDataset(ts_tensor_x, ts_tensor_y) # create your datset\n",
        "ts_dataloader = DataLoader(ts_dataset, batch_size=BATCH_SIZE) # create your dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geg_4oapCEHs"
      },
      "source": [
        "## The Neural Network\n",
        "\n",
        "### Defining the Training\n",
        "\n",
        "\n",
        "Neural Network တခုကို train တဲ့အခါမှာ component ၃ ခုက အရေးကြီးပါတယ်။ \n",
        "\n",
        "1. Neural Network Definition\n",
        "2. Optimizer\n",
        "3. Loss function (`criterion`)\n",
        "\n",
        "ပထမဆုံး Neural Network ရဲ့ definition ဟာ အရေးအကြီးဆုံးပါပဲ။ ဒီနေရာမှာ တချိန်က နာမည်ကြီးခဲ့တဲ့ LeNet5 ကို သုံးပါမယ်။ \n",
        "\n",
        "1. Layer 1 (C1): The first convolutional layer with 6 kernels of size 5×5 and the stride of 1. \n",
        "   \n",
        "   Given the input size (48×48×1), the output of this layer is of size 44×44×6.\n",
        "\n",
        "2. Layer 2 (S2): A subsampling/pooling layer with 6 kernels of size 2×2 and the stride of 2. The subsampling layer in the original architecture was a bit more complex than the traditionally used max/average pooling layers. I will quote the original paper: \n",
        "   \n",
        "   > “ The four inputs to a unit in S2 are added, then multiplied by a trainable coefficient, and added to a trainable bias. The result is passed through a sigmoidal function.”. \n",
        "   \n",
        "   As a result of non-overlapping receptive fields, the input to this layer is 1/4th in size (22×22×6).\n",
        "\n",
        "3. Layer 3 (C3): The second convolutional layer with the same configuration as the first one, however, this time with 16 filters. The output of this layer is 18x18x16.\n",
        "\n",
        "4. Layer 4 (S4): The second pooling layer. The logic is identical to the previous one, but this time the layer has 16 filters. \n",
        "   \n",
        "   The output of this layer is of size 9×9×16.\n",
        "\n",
        "5. Layer 5 (C5): The last convolutional layer with 20 5×5 kernels. \n",
        "   \n",
        "   Given that the input to this layer is of size 9×9×16 and the kernels are of size 9×9, the output is 1×1×120. \n",
        "\n",
        "6. Layer 6 (F6): The first fully-connected layer, which takes the input of 120 units and returns 84 units. In the original paper, the authors used a custom activation function — a variant of the tanh activation function. \n",
        "\n",
        "7. Layer 7 (F7): The last dense layer, which outputs 10 units. In original paper, the authors used Euclidean Radial Basis Function neurons as activation functions for this layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSti_12D0kZ4"
      },
      "outputs": [],
      "source": [
        "#Defining the convolutional neural network\n",
        "class LeNet5(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(LeNet5, self).__init__()\n",
        "        \n",
        "        self.feature_extractor = nn.Sequential(            \n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1), # C1\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2), # S2\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1), #C3\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2), # S4\n",
        "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1), #C5\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=120, out_features=84), #F6\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=84, out_features=n_classes), #F7\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print (x.size())\n",
        "        x = x.unsqueeze(1)\n",
        "        # print (x.size())\n",
        "        x = self.feature_extractor(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        return logits, probs\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = LeNet5(N_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Actual training\n",
        "\n",
        "Neural Network ကို define ပြီးရင် training စပါမယ်။ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "_z8Bx4g2Bkhs",
        "outputId": "43a4b5bc-ebe2-4bb8-f21e-e3ddc77566c5"
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "def get_accuracy(model, data_loader, device):\n",
        "    '''\n",
        "    Function for computing the accuracy of the predictions over the entire data_loader\n",
        "    '''\n",
        "    \n",
        "    correct_pred = 0 \n",
        "    n = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for X, y_true in data_loader:\n",
        "\n",
        "            X = X.to(device)\n",
        "            y_true = y_true.to(device)\n",
        "\n",
        "            _, y_prob = model(X)\n",
        "            _, predicted_labels = torch.max(y_prob, 1)\n",
        "\n",
        "            n += y_true.size(0)\n",
        "            correct_pred += (predicted_labels == y_true).sum()\n",
        "\n",
        "    return correct_pred.float() / n\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, device):\n",
        "    '''\n",
        "    Function for the training step of the training loop\n",
        "    '''\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    \n",
        "    for X, y_true in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        X = X.to(device)\n",
        "        y_true = y_true.to(device)\n",
        "    \n",
        "        # Forward pass\n",
        "        y_hat, _ = model(X) \n",
        "        loss = criterion(y_hat, y_true) \n",
        "\n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    return model, optimizer, epoch_loss\n",
        "\n",
        "def validate(valid_loader, model, criterion, device):\n",
        "    '''\n",
        "    Function for the validation step of the training loop\n",
        "    '''\n",
        "   \n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    \n",
        "    for X, y_true in valid_loader:\n",
        "    \n",
        "        X = X.to(device)\n",
        "        y_true = y_true.to(device)\n",
        "\n",
        "        # Forward pass and record loss\n",
        "        y_hat, _ = model(X) \n",
        "        loss = criterion(y_hat, y_true) \n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
        "        \n",
        "    return model, epoch_loss\n",
        "\n",
        "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
        "    '''\n",
        "    Function defining the entire training loop\n",
        "    '''\n",
        "    \n",
        "    # set objects for storing metrics\n",
        "    best_loss = 1e10\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        " \n",
        "    # Train model\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        # training\n",
        "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # validation\n",
        "        with torch.no_grad():\n",
        "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
        "            valid_losses.append(valid_loss)\n",
        "\n",
        "        if epoch % print_every == (print_every - 1):\n",
        "            \n",
        "            train_acc = get_accuracy(model, train_loader, device=device)\n",
        "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
        "                \n",
        "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
        "                  f'Epoch: {epoch}\\t'\n",
        "                  f'Train loss: {train_loss:.4f}\\t'\n",
        "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
        "                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
        "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
        "    \n",
        "    return model, optimizer, (train_losses, valid_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model, optimizer, _ = training_loop(\n",
        "    model=model, \n",
        "    criterion=criterion, \n",
        "    optimizer=optimizer, \n",
        "    train_loader=my_dataloader, \n",
        "    valid_loader=ts_dataloader, \n",
        "    epochs=N_EPOCHS, \n",
        "    device=DEVICE,\n",
        "    print_every=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finally, evaluate\n",
        "\n",
        "Evaluate လုပ်ဖို့ test set ကို model ထဲ ထည့်ရမယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "_x2mZxFpF8K7",
        "outputId": "39607762-8277-48d9-9175-ba5e074f3def"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "ts_tensor_x_ = ts_tensor_x.to(DEVICE)\n",
        "\n",
        "y_hat, probs = model(ts_tensor_x_) \n",
        "y_hat = y_hat.argmax(dim=1)\n",
        "pred_y = y_hat.cpu().detach().numpy()\n",
        "\n",
        "print (metrics.classification_report(ts_y, pred_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjTqb_YZSFp1"
      },
      "outputs": [],
      "source": [
        "print (metrics.confusion_matrix(ts_y, pred_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Myanmar-Digits.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('py37-dsup')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3a9c1e998c7d6d5f29587b2c70e9bd488bb486b902354401efc27ca8457f04e9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
