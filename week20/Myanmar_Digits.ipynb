{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 20 - Outro\n",
        "\n",
        "မင်္ဂလာပါ၊ ဒီနေ့ နောက်ဆုံးပိတ် အိတ်နဲ့လွယ် ... Neural Network တွေကို စမ်းရေး၊ စမ်းသုံးကြည့်ကြမယ်။ \n",
        "\n",
        "ပထမဆုံး ရင်းနှီးပြီးသားဖြစ်တဲ့ myanmar-digits နဲ့ စပါမယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggRYFMDmxl49",
        "outputId": "5b00842d-4099-4885-ac61-3701f72b75fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'myanmar-digits'...\n",
            "remote: Enumerating objects: 97, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 97 (delta 0), reused 8 (delta 0), pack-reused 86\u001b[K\n",
            "Unpacking objects: 100% (97/97), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/neolaw84/myanmar-digits.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D1AsNbgxqfi",
        "outputId": "7ab69256-2ac3-41de-e8e3-c939829b3938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/edward/projects/myanmar-digits\n"
          ]
        }
      ],
      "source": [
        "%cd /home/edward/projects/myanmar-digits\n",
        "#%cd myanmar-digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA7H9pbmyfD6",
        "outputId": "216a15de-8cd7-4e26-d9dc-9681f8f67aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.7.3)\n",
            "Requirement already satisfied: numpy in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.0.2)\n",
            "Requirement already satisfied: matplotlib in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (3.5.2)\n",
            "Requirement already satisfied: pandas in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.3.5)\n",
            "Requirement already satisfied: pillow in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (9.2.0)\n",
            "Requirement already satisfied: opencv-python in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n",
            "Requirement already satisfied: fire in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (0.4.0)\n",
            "Requirement already satisfied: tqdm in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (4.64.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from scikit-learn->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 4)) (21.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 4)) (4.34.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 5)) (2022.1)\n",
            "Requirement already satisfied: termcolor in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from fire->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: six in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from fire->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions in /home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->-r requirements.txt (line 4)) (4.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DETx3lsDx4v_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from datetime import datetime \n",
        "\n",
        "from sklearn import feature_selection as fs, model_selection as ms, metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from myanmar_digits import load_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparation\n",
        "\n",
        "### Import necessary modules\n",
        "\n",
        "Neural Network ကို **pytorch** library ကို အသုံးပြုပြီး ရေးသားပါမယ်။ \n",
        "\n",
        "ဒီအတွက် `torch`, `torch.nn` နဲ့ `torchvision` တို့ထဲက လိုအပ်တာတွေကို import လုပ်ပါတယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# check device to use CUDA (GPU programming) if available\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set parameters\n",
        "\n",
        "Neural Network တခုမှာ အရေးပါတဲ့ parameter တွေကတော့\n",
        "\n",
        "* learning_rate \n",
        "* batch_size နဲ့\n",
        "* number_of_epoch တို့ပဲ ဖြစ်တယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YZSVTKGGyV6E"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "RANDOM_SEED = 42\n",
        "LEARNING_RATE = 0.002\n",
        "BATCH_SIZE = 4\n",
        "N_EPOCHS = 50\n",
        "\n",
        "IMG_SIZE = 48\n",
        "N_CLASSES = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data\n",
        "\n",
        "Data ကို load လုပ်ပါမယ်။ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX7Iv4BEaWVZ",
        "outputId": "4ddc7bbf-ff11-4271-e1cd-6451c97100a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4498, 2304), (4498,))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y = load_data(as_frame=False, return_X_y=True, num_classes=N_CLASSES)\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`torch` က `sklearn` လို မဟုတ်ပဲ 2D data structure (2d tensor) တင်မက 3D data structure (3d tensor) နဲ့ အဆင့်မြင့် kD data structure တွေကိုပါ ကိုင်တွယ်နိုင်တာမို့ရယ်၊ convolution လုပ်ချင်တာမို့ရယ် `X` ကို တလက်စတည်း 48x48 image တွေပါတဲ့ array ကြီးအဖြစ် `reshape` လုပ်လိုက်ပါတယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R2_ZsIrxawCT"
      },
      "outputs": [],
      "source": [
        "X = (255 - X)/255.0\n",
        "X = X.reshape( -1, 48, 48 )\n",
        "y = y.astype(np.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "_wVc0vowbhMX",
        "outputId": "fa33febf-ecda-43e0-cd75-eb3d31fa571a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(X[1000], cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = X[:, 8:-8, 8:-8]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train/Test splitting\n",
        "\n",
        "data ကို load လုပ်ပြီးရင် မမေ့မလျော့ train/test split လုပ်ပါ။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sg_tWIbgeB54"
      },
      "outputs": [],
      "source": [
        "tr_X, ts_X, tr_y, ts_y = ms.train_test_split(X, y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create DataLoaders\n",
        "\n",
        "နောက်တဆင့်မှာ torch ကသုံးတဲ့ DataLoader တွေအဖြစ်ကို အသွင်ပြောင်းရပါမယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KuClhAVfz6KF"
      },
      "outputs": [],
      "source": [
        "tr_tensor_x = torch.Tensor(tr_X) # transform to torch tensor\n",
        "tr_tensor_y = torch.Tensor(tr_y).long()\n",
        "\n",
        "ts_tensor_x = torch.Tensor(ts_X) # transform to torch tensor\n",
        "ts_tensor_y = torch.Tensor(ts_y).long()\n",
        "\n",
        "my_dataset = TensorDataset(tr_tensor_x, tr_tensor_y) # create your datset\n",
        "my_dataloader = DataLoader(my_dataset, batch_size=BATCH_SIZE) # create your dataloader\n",
        "\n",
        "ts_dataset = TensorDataset(ts_tensor_x, ts_tensor_y) # create your datset\n",
        "ts_dataloader = DataLoader(ts_dataset, batch_size=BATCH_SIZE) # create your dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geg_4oapCEHs"
      },
      "source": [
        "## The Neural Network\n",
        "\n",
        "### Defining the Training\n",
        "\n",
        "\n",
        "Neural Network တခုကို train တဲ့အခါမှာ component ၃ ခုက အရေးကြီးပါတယ်။ \n",
        "\n",
        "1. Neural Network Definition\n",
        "2. Optimizer\n",
        "3. Loss function (`criterion`)\n",
        "\n",
        "ပထမဆုံး Neural Network ရဲ့ definition ဟာ အရေးအကြီးဆုံးပါပဲ။ ဒီနေရာမှာ တချိန်က နာမည်ကြီးခဲ့တဲ့ LeNet5 ကို သုံးပါမယ်။ \n",
        "\n",
        "1. Layer 1 (C1): The first convolutional layer with 6 kernels of size 5×5 and the stride of 1. \n",
        "   \n",
        "   Given the input size (48×48×1), the output of this layer is of size 44×44×6.\n",
        "\n",
        "2. Layer 2 (S2): A subsampling/pooling layer with 6 kernels of size 2×2 and the stride of 2. The subsampling layer in the original architecture was a bit more complex than the traditionally used max/average pooling layers. I will quote the original paper: \n",
        "   \n",
        "   > “ The four inputs to a unit in S2 are added, then multiplied by a trainable coefficient, and added to a trainable bias. The result is passed through a sigmoidal function.”. \n",
        "   \n",
        "   As a result of non-overlapping receptive fields, the input to this layer is 1/4th in size (22×22×6).\n",
        "\n",
        "3. Layer 3 (C3): The second convolutional layer with the same configuration as the first one, however, this time with 16 filters. The output of this layer is 18x18x16.\n",
        "\n",
        "4. Layer 4 (S4): The second pooling layer. The logic is identical to the previous one, but this time the layer has 16 filters. \n",
        "   \n",
        "   The output of this layer is of size 9×9×16.\n",
        "\n",
        "5. Layer 5 (C5): The last convolutional layer with 20 5×5 kernels. \n",
        "   \n",
        "   Given that the input to this layer is of size 9×9×16 and the kernels are of size 9×9, the output is 1×1×120. \n",
        "\n",
        "6. Layer 6 (F6): The first fully-connected layer, which takes the input of 120 units and returns 84 units. In the original paper, the authors used a custom activation function — a variant of the tanh activation function. \n",
        "\n",
        "7. Layer 7 (F7): The last dense layer, which outputs 10 units. In original paper, the authors used Euclidean Radial Basis Function neurons as activation functions for this layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DSti_12D0kZ4"
      },
      "outputs": [],
      "source": [
        "#Defining the convolutional neural network\n",
        "class LeNet5(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(LeNet5, self).__init__()\n",
        "        \n",
        "        self.feature_extractor = nn.Sequential(            \n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1), # C1\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2), # S2\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1), #C3\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2), # S4\n",
        "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1), #C5\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=120, out_features=84), #F6\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=84, out_features=n_classes), #F7\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print (x.size())\n",
        "        x = x.unsqueeze(1)\n",
        "        # print (x.size())\n",
        "        x = self.feature_extractor(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        return logits, probs\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = LeNet5(N_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Actual training\n",
        "\n",
        "Neural Network ကို define ပြီးရင် training စပါမယ်။ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "_z8Bx4g2Bkhs",
        "outputId": "43a4b5bc-ebe2-4bb8-f21e-e3ddc77566c5"
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "def get_accuracy(model, data_loader, device):\n",
        "    '''\n",
        "    Function for computing the accuracy of the predictions over the entire data_loader\n",
        "    '''\n",
        "    \n",
        "    correct_pred = 0 \n",
        "    n = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for X, y_true in data_loader:\n",
        "\n",
        "            X = X.to(device)\n",
        "            y_true = y_true.to(device)\n",
        "\n",
        "            _, y_prob = model(X)\n",
        "            _, predicted_labels = torch.max(y_prob, 1)\n",
        "\n",
        "            n += y_true.size(0)\n",
        "            correct_pred += (predicted_labels == y_true).sum()\n",
        "\n",
        "    return correct_pred.float() / n\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, device):\n",
        "    '''\n",
        "    Function for the training step of the training loop\n",
        "    '''\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    \n",
        "    for X, y_true in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        X = X.to(device)\n",
        "        y_true = y_true.to(device)\n",
        "    \n",
        "        # Forward pass\n",
        "        y_hat, _ = model(X) \n",
        "        loss = criterion(y_hat, y_true) \n",
        "\n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    return model, optimizer, epoch_loss\n",
        "\n",
        "def validate(valid_loader, model, criterion, device):\n",
        "    '''\n",
        "    Function for the validation step of the training loop\n",
        "    '''\n",
        "   \n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    \n",
        "    for X, y_true in valid_loader:\n",
        "    \n",
        "        X = X.to(device)\n",
        "        y_true = y_true.to(device)\n",
        "\n",
        "        # Forward pass and record loss\n",
        "        y_hat, _ = model(X) \n",
        "        loss = criterion(y_hat, y_true) \n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
        "        \n",
        "    return model, epoch_loss\n",
        "\n",
        "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
        "    '''\n",
        "    Function defining the entire training loop\n",
        "    '''\n",
        "    \n",
        "    # set objects for storing metrics\n",
        "    best_loss = 1e10\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        " \n",
        "    # Train model\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        # training\n",
        "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # validation\n",
        "        with torch.no_grad():\n",
        "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
        "            valid_losses.append(valid_loss)\n",
        "\n",
        "        if epoch % print_every == (print_every - 1):\n",
        "            \n",
        "            train_acc = get_accuracy(model, train_loader, device=device)\n",
        "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
        "                \n",
        "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
        "                  f'Epoch: {epoch}\\t'\n",
        "                  f'Train loss: {train_loss:.4f}\\t'\n",
        "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
        "                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
        "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
        "    \n",
        "    return model, optimizer, (train_losses, valid_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20:38:10 --- Epoch: 0\tTrain loss: 0.5919\tValid loss: 0.6401\tTrain accuracy: 84.85\tValid accuracy: 78.84\n",
            "20:38:15 --- Epoch: 1\tTrain loss: 0.4383\tValid loss: 0.5546\tTrain accuracy: 87.67\tValid accuracy: 80.36\n",
            "20:38:20 --- Epoch: 2\tTrain loss: 0.3723\tValid loss: 0.5735\tTrain accuracy: 88.32\tValid accuracy: 81.51\n",
            "20:38:25 --- Epoch: 3\tTrain loss: 0.2981\tValid loss: 0.5561\tTrain accuracy: 89.80\tValid accuracy: 82.67\n",
            "20:38:31 --- Epoch: 4\tTrain loss: 0.2575\tValid loss: 0.5394\tTrain accuracy: 91.25\tValid accuracy: 82.58\n",
            "20:38:37 --- Epoch: 5\tTrain loss: 0.2583\tValid loss: 0.4542\tTrain accuracy: 93.66\tValid accuracy: 87.02\n",
            "20:38:42 --- Epoch: 6\tTrain loss: 0.2208\tValid loss: 0.5113\tTrain accuracy: 93.27\tValid accuracy: 86.13\n",
            "20:38:48 --- Epoch: 7\tTrain loss: 0.1866\tValid loss: 0.5879\tTrain accuracy: 92.20\tValid accuracy: 83.20\n",
            "20:38:53 --- Epoch: 8\tTrain loss: 0.1630\tValid loss: 0.5242\tTrain accuracy: 94.78\tValid accuracy: 87.38\n",
            "20:38:58 --- Epoch: 9\tTrain loss: 0.1790\tValid loss: 0.5185\tTrain accuracy: 94.40\tValid accuracy: 87.47\n",
            "20:39:03 --- Epoch: 10\tTrain loss: 0.1674\tValid loss: 0.5431\tTrain accuracy: 94.87\tValid accuracy: 86.93\n",
            "20:39:09 --- Epoch: 11\tTrain loss: 0.1743\tValid loss: 0.5711\tTrain accuracy: 93.92\tValid accuracy: 86.13\n",
            "20:39:15 --- Epoch: 12\tTrain loss: 0.1603\tValid loss: 0.5830\tTrain accuracy: 94.75\tValid accuracy: 85.96\n",
            "20:39:21 --- Epoch: 13\tTrain loss: 0.1423\tValid loss: 0.4862\tTrain accuracy: 96.50\tValid accuracy: 89.16\n",
            "20:39:26 --- Epoch: 14\tTrain loss: 0.1173\tValid loss: 0.5757\tTrain accuracy: 95.91\tValid accuracy: 86.93\n",
            "20:39:32 --- Epoch: 15\tTrain loss: 0.1228\tValid loss: 0.6322\tTrain accuracy: 95.76\tValid accuracy: 85.51\n",
            "20:39:38 --- Epoch: 16\tTrain loss: 0.1105\tValid loss: 0.5554\tTrain accuracy: 95.91\tValid accuracy: 87.02\n",
            "20:39:43 --- Epoch: 17\tTrain loss: 0.1591\tValid loss: 0.6721\tTrain accuracy: 93.27\tValid accuracy: 83.56\n",
            "20:39:48 --- Epoch: 18\tTrain loss: 0.1278\tValid loss: 0.6226\tTrain accuracy: 96.12\tValid accuracy: 86.67\n",
            "20:39:53 --- Epoch: 19\tTrain loss: 0.1133\tValid loss: 0.5475\tTrain accuracy: 96.86\tValid accuracy: 88.36\n",
            "20:39:58 --- Epoch: 20\tTrain loss: 0.0939\tValid loss: 0.5777\tTrain accuracy: 96.35\tValid accuracy: 87.56\n",
            "20:40:03 --- Epoch: 21\tTrain loss: 0.0893\tValid loss: 0.5522\tTrain accuracy: 97.18\tValid accuracy: 88.89\n",
            "20:40:07 --- Epoch: 22\tTrain loss: 0.0888\tValid loss: 0.5916\tTrain accuracy: 96.92\tValid accuracy: 89.07\n",
            "20:40:12 --- Epoch: 23\tTrain loss: 0.1155\tValid loss: 0.6671\tTrain accuracy: 96.41\tValid accuracy: 87.11\n",
            "20:40:17 --- Epoch: 24\tTrain loss: 0.0915\tValid loss: 0.6275\tTrain accuracy: 97.01\tValid accuracy: 88.09\n",
            "20:40:24 --- Epoch: 25\tTrain loss: 0.1306\tValid loss: 0.6055\tTrain accuracy: 95.85\tValid accuracy: 87.56\n",
            "20:40:29 --- Epoch: 26\tTrain loss: 0.0829\tValid loss: 0.6240\tTrain accuracy: 97.72\tValid accuracy: 87.47\n",
            "20:40:35 --- Epoch: 27\tTrain loss: 0.0747\tValid loss: 0.5834\tTrain accuracy: 97.69\tValid accuracy: 89.96\n",
            "20:40:40 --- Epoch: 28\tTrain loss: 0.0886\tValid loss: 0.6688\tTrain accuracy: 95.94\tValid accuracy: 85.60\n",
            "20:40:45 --- Epoch: 29\tTrain loss: 0.0891\tValid loss: 0.6697\tTrain accuracy: 96.06\tValid accuracy: 87.64\n",
            "20:40:50 --- Epoch: 30\tTrain loss: 0.0976\tValid loss: 0.6715\tTrain accuracy: 95.79\tValid accuracy: 86.67\n",
            "20:40:54 --- Epoch: 31\tTrain loss: 0.0937\tValid loss: 0.5530\tTrain accuracy: 97.98\tValid accuracy: 89.16\n",
            "20:41:00 --- Epoch: 32\tTrain loss: 0.0928\tValid loss: 0.6656\tTrain accuracy: 96.32\tValid accuracy: 85.96\n",
            "20:41:05 --- Epoch: 33\tTrain loss: 0.1083\tValid loss: 0.6225\tTrain accuracy: 97.39\tValid accuracy: 88.44\n",
            "20:41:11 --- Epoch: 34\tTrain loss: 0.0674\tValid loss: 0.6339\tTrain accuracy: 98.46\tValid accuracy: 88.80\n",
            "20:41:16 --- Epoch: 35\tTrain loss: 0.0896\tValid loss: 0.6456\tTrain accuracy: 97.39\tValid accuracy: 88.09\n",
            "20:41:21 --- Epoch: 36\tTrain loss: 0.0971\tValid loss: 0.6745\tTrain accuracy: 97.75\tValid accuracy: 87.64\n",
            "20:41:27 --- Epoch: 37\tTrain loss: 0.0913\tValid loss: 0.6833\tTrain accuracy: 97.33\tValid accuracy: 88.09\n",
            "20:41:32 --- Epoch: 38\tTrain loss: 0.0813\tValid loss: 0.5674\tTrain accuracy: 98.84\tValid accuracy: 90.04\n",
            "20:41:38 --- Epoch: 39\tTrain loss: 0.0748\tValid loss: 0.6843\tTrain accuracy: 97.06\tValid accuracy: 86.67\n",
            "20:41:43 --- Epoch: 40\tTrain loss: 0.1152\tValid loss: 0.7224\tTrain accuracy: 97.15\tValid accuracy: 86.13\n",
            "20:41:49 --- Epoch: 41\tTrain loss: 0.0765\tValid loss: 0.6697\tTrain accuracy: 98.46\tValid accuracy: 87.56\n",
            "20:41:54 --- Epoch: 42\tTrain loss: 0.0713\tValid loss: 0.6599\tTrain accuracy: 97.81\tValid accuracy: 87.56\n",
            "20:42:00 --- Epoch: 43\tTrain loss: 0.0966\tValid loss: 0.7310\tTrain accuracy: 97.27\tValid accuracy: 86.58\n",
            "20:42:04 --- Epoch: 44\tTrain loss: 0.0664\tValid loss: 0.6372\tTrain accuracy: 98.64\tValid accuracy: 88.53\n",
            "20:42:10 --- Epoch: 45\tTrain loss: 0.0768\tValid loss: 0.7132\tTrain accuracy: 97.39\tValid accuracy: 87.11\n",
            "20:42:16 --- Epoch: 46\tTrain loss: 0.0727\tValid loss: 0.7267\tTrain accuracy: 98.40\tValid accuracy: 88.98\n",
            "20:42:21 --- Epoch: 47\tTrain loss: 0.0748\tValid loss: 0.7164\tTrain accuracy: 98.13\tValid accuracy: 88.00\n",
            "20:42:26 --- Epoch: 48\tTrain loss: 0.0937\tValid loss: 0.6806\tTrain accuracy: 98.01\tValid accuracy: 87.91\n",
            "20:42:32 --- Epoch: 49\tTrain loss: 0.0558\tValid loss: 0.6410\tTrain accuracy: 98.16\tValid accuracy: 86.58\n"
          ]
        }
      ],
      "source": [
        "model, optimizer, _ = training_loop(\n",
        "    model=model, \n",
        "    criterion=criterion, \n",
        "    optimizer=optimizer, \n",
        "    train_loader=my_dataloader, \n",
        "    valid_loader=ts_dataloader, \n",
        "    epochs=N_EPOCHS, \n",
        "    device=DEVICE,\n",
        "    print_every=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finally, evaluate\n",
        "\n",
        "Evaluate လုပ်ဖို့ test set ကို model ထဲ ထည့်ရမယ်။"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "_x2mZxFpF8K7",
        "outputId": "39607762-8277-48d9-9175-ba5e074f3def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.70      0.76        44\n",
            "           1       0.75      0.77      0.76        47\n",
            "           2       0.94      0.93      0.93       108\n",
            "           3       0.92      0.95      0.93       149\n",
            "           4       0.98      0.92      0.95       154\n",
            "           5       0.82      0.83      0.83       188\n",
            "           6       0.82      0.86      0.84       125\n",
            "           7       0.83      0.82      0.83       123\n",
            "           8       0.79      0.89      0.84       100\n",
            "           9       0.87      0.83      0.85        87\n",
            "\n",
            "    accuracy                           0.87      1125\n",
            "   macro avg       0.86      0.85      0.85      1125\n",
            "weighted avg       0.87      0.87      0.87      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "ts_tensor_x_ = ts_tensor_x.to(DEVICE)\n",
        "\n",
        "y_hat, probs = model(ts_tensor_x_) \n",
        "y_hat = y_hat.argmax(dim=1)\n",
        "pred_y = y_hat.cpu().detach().numpy()\n",
        "\n",
        "print (metrics.classification_report(ts_y, pred_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "mjTqb_YZSFp1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 31   2   0   0   0   0   2   0   9   0]\n",
            " [  4  36   3   0   0   2   0   0   2   0]\n",
            " [  0   2 100   2   0   2   0   1   0   1]\n",
            " [  0   2   2 141   0   0   0   1   0   3]\n",
            " [  0   2   0   3 141   5   0   3   0   0]\n",
            " [  0   0   1   2   0 156  13  10   5   1]\n",
            " [  0   2   0   1   0   7 107   3   2   3]\n",
            " [  0   1   0   0   3  15   1 101   1   1]\n",
            " [  3   0   0   1   0   1   4   0  89   2]\n",
            " [  0   1   0   3   0   2   3   2   4  72]]\n"
          ]
        }
      ],
      "source": [
        "print (metrics.confusion_matrix(ts_y, pred_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Myanmar-Digits.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('py37-dsup')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3a9c1e998c7d6d5f29587b2c70e9bd488bb486b902354401efc27ca8457f04e9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
