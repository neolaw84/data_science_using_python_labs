{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "Dimensionality Reduction အများစုက တွေ့ဖူးခဲ့ပြီးသားပါ။ \n",
    "\n",
    "* SVD (not to be confused with SVM)\n",
    "* PCA\n",
    "* Fast Fourier Transform နဲ့ \n",
    "* KMean centroid distane method တို့ ဖြစ်ကြတယ်။"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "df_X, ds_y = datasets.load_digits(as_frame=True, return_X_y=True)\n",
    "\n",
    "U, s, Vt = linalg.svd(df_X.values.T)\n",
    "\n",
    "k = 32 # or any number less than large_2d_array.shape[1]\n",
    "s_ = s[:k]\n",
    "Vt_ = Vt[:k,:]\n",
    "\n",
    "Sigma = linalg.diagsvd(s_, U.shape[1], Vt_.shape[0])\n",
    "smaller_version = df_X.values @ Sigma\n",
    "df_X.shape, smaller_version.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset consists of 400 faces\n",
      "(400, 4096)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from numpy.random import RandomState\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn import cluster\n",
    "from sklearn import decomposition\n",
    "\n",
    "rng = RandomState(0)\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "faces, fy = fetch_olivetti_faces(return_X_y=True, shuffle=True, random_state=rng)\n",
    "n_samples, n_features = faces.shape\n",
    "\n",
    "# Global centering (focus on one feature, centering all samples)\n",
    "faces_centered = faces - faces.mean(axis=0)\n",
    "\n",
    "# Local centering (focus on one sample, centering all features)\n",
    "faces_centered -= faces_centered.mean(axis=1).reshape(n_samples, -1)\n",
    "\n",
    "print(\"Dataset consists of %d faces\" % n_samples)\n",
    "print(faces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row, n_col = 2, 3\n",
    "n_components = n_row * n_col\n",
    "image_shape = (64, 64)\n",
    "\n",
    "\n",
    "def plot_gallery(title, images, n_col=n_col, n_row=n_row, cmap=plt.cm.gray):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=n_row,\n",
    "        ncols=n_col,\n",
    "        figsize=(2.0 * n_col, 2.3 * n_row),\n",
    "        facecolor=\"white\",\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "    fig.set_constrained_layout_pads(w_pad=0.01, h_pad=0.02, hspace=0, wspace=0)\n",
    "    fig.set_edgecolor(\"black\")\n",
    "    fig.suptitle(title, size=16)\n",
    "    for ax, vec in zip(axs.flat, images):\n",
    "        vmax = max(vec.max(), -vec.min())\n",
    "        im = ax.imshow(\n",
    "            vec.reshape(image_shape),\n",
    "            cmap=cmap,\n",
    "            interpolation=\"nearest\",\n",
    "            vmin=-vmax,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.colorbar(im, ax=axs, orientation=\"horizontal\", shrink=0.99, aspect=40, pad=0.01)\n",
    "    plt.show()\n",
    "\n",
    "plot_gallery(\"Faces from dataset\", faces_centered[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_estimator = decomposition.PCA(\n",
    "    n_components=n_components, svd_solver=\"randomized\", whiten=True\n",
    ")\n",
    "pca_estimator.fit(faces_centered)\n",
    "plot_gallery(\n",
    "    \"Eigenfaces - PCA using randomized SVD\", pca_estimator.components_[:n_components]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_faces = pca_estimator.transform(faces_centered)\n",
    "reduced_faces.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined with `SVM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pre\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=150, svd_solver='randomized', whiten=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = 150\n",
    "\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(\n",
    "    faces, fy, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "scaler = pre.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pca = decomposition.PCA(n_components=n_components, svd_solver=\"randomized\", whiten=True)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4096)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projecting the input data on the eigenfaces orthonormal basis\n"
     ]
    }
   ],
   "source": [
    "eigenfaces = pca.components_.reshape((n_components, 64, 64))\n",
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      0.25      0.40         4\n",
      "           3       1.00      1.00      1.00         1\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      0.80      0.89         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       1.00      1.00      1.00         1\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       1.00      1.00      1.00         2\n",
      "          15       1.00      0.67      0.80         3\n",
      "          16       0.67      1.00      0.80         2\n",
      "          17       0.50      1.00      0.67         1\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       0.57      1.00      0.73         4\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       0.67      1.00      0.80         2\n",
      "          24       1.00      1.00      1.00         1\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          29       1.00      1.00      1.00         1\n",
      "          30       1.00      1.00      1.00         5\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       1.00      1.00      1.00         1\n",
      "          33       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         4\n",
      "          36       1.00      1.00      1.00         5\n",
      "          37       1.00      1.00      1.00         3\n",
      "          38       1.00      1.00      1.00         5\n",
      "          39       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.93      0.92      0.91       100\n",
      "weighted avg       0.96      0.93      0.93       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/edward/anaconda3/envs/py37-dsup/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel=\"rbf\", C=76823.03433306453, class_weight='balanced', gamma=0.003418945823095797)\n",
    "model.fit(X_train_pca, y_train)\n",
    "pred = model.predict(X_test_pca)\n",
    "print (metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "msft = yf.Ticker(\"MSFT\")\n",
    "\n",
    "# get historical market data\n",
    "hist = msft.history(period=\"max\")\n",
    "print (type(hist))\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import fft\n",
    "\n",
    "NUM_DAYS = 1500\n",
    "\n",
    "close = hist.Close[-NUM_DAYS:].values\n",
    "frequencies = fft.fft(close)\n",
    "plt.plot(np.log(frequencies))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_ = frequencies.copy()\n",
    "frequencies_[50:1450] = 0\n",
    "print (np.count_nonzero(frequencies_))\n",
    "print (len(frequencies_))\n",
    "plt.plot(np.log(frequencies_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_ = fft.ifft(frequencies_)\n",
    "plt.plot(hist.index[-NUM_DAYS:], close_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (frequencies_.shape)\n",
    "frequencies_dict = {k: v for k, v in enumerate(frequencies_) if v > 0}\n",
    "print (len(frequencies_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans Centroid Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, tree, cluster, model_selection, metrics\n",
    "\n",
    "# 1. load the data\n",
    "df_X, ds_y = datasets.load_digits(n_class=2, return_X_y=True, as_frame=True)\n",
    "\n",
    "# 2. split into train and test sets\n",
    "tr_X, ts_X, tr_y, ts_y = model_selection.train_test_split(df_X, ds_y, random_state=42)\n",
    "\n",
    "# 3. some feature engineering\n",
    "kmean = cluster.KMeans()\n",
    "feat_tr_X = kmean.fit_transform(tr_X)\n",
    "feat_ts_X = kmean.transform(ts_X)\n",
    "\n",
    "# 4. build tree model\n",
    "tree_model = tree.DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=3, max_features=3, max_leaf_nodes=3, random_state=24)\n",
    "tree_model.fit(feat_tr_X, tr_y)\n",
    "\n",
    "# 5. test the model\n",
    "pred_y = tree_model.predict(feat_ts_X)\n",
    "\n",
    "print (metrics.classification_report(y_true=ts_y, y_pred=pred_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('py37-dsup')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a9c1e998c7d6d5f29587b2c70e9bd488bb486b902354401efc27ca8457f04e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
